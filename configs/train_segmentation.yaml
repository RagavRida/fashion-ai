# ──────────────────────────────────────────────────
# Fashion Reuse Studio — Segmentation CNN Config
# ──────────────────────────────────────────────────

model:
  architecture: "unet"        # unet | mask_rcnn
  encoder: "resnet34"         # resnet18 | resnet34 | resnet50
  pretrained_encoder: true
  in_channels: 3
  num_classes: 1              # binary: garment vs background (BCE loss)
  output_dir: "checkpoints/garment_segmentation.pth"

training:
  output_dir: "checkpoints/segmentation"
  logging_dir: "outputs/logs/segmentation"
  resolution: 512
  train_batch_size: 32        # larger batch = faster on A100
  num_train_epochs: 15        # budget: 15 instead of 50
  learning_rate: 1.0e-4
  lr_scheduler: "reduce_on_plateau"
  lr_scheduler_patience: 5
  lr_scheduler_factor: 0.5
  adam_weight_decay: 1.0e-4
  max_grad_norm: 5.0
  early_stopping_patience: 5
  max_train_samples: 10000    # budget: 10K subset

  # Loss
  loss: "combo"               # bce | dice | combo | focal_dice
  dice_weight: 0.5
  bce_weight: 0.5

augmentation:
  horizontal_flip: true
  vertical_flip: false
  random_rotation: 10
  color_jitter: 0.2
  elastic_transform: false
  grid_distortion: false

precision:
  mixed_precision: "fp16"
  gradient_checkpointing: false

checkpointing:
  save_epoch_frequency: 5
  save_total_limit: 3

logging:
  report_to: "wandb"
  wandb_project: "fashion-reuse-studio"
  wandb_run_name: "segmentation-unet"
  logging_steps: 50

metrics:
  names:
    - "iou"
    - "dice"
    - "pixel_accuracy"
  target_iou: 0.70


data:
  train_data_dir: "data/processed"
  metadata_file: "data/processed/metadata.jsonl"
  image_column: "image_path"
  mask_column: "mask_path"
  dataloader_num_workers: 8
  val_split: 0.1
